---
guardianId: >-
  technology/2025/aug/23/expert-rejects-met-police-claim-that-study-backs-bias-free-live-facial-recognition-use
webTitle: >-
  Expert rejects Met police claim that study backs bias-free live facial
  recognition use
sectionName: Technology
webPublicationDate: '2025-08-23T06:00:57Z'
bodyText: >-
  The Metropolitan police’s claims that their use of live facial recognition is
  bias-free are not substantiated by the report they cite to support their case,
  a leading expert on the technology has said. The Met is planning its biggest
  and most high profile use of LFR yet this bank holiday weekend at Notting Hill
  carnival in west London. The Guardian understands it will be deployed at two
  sites on the approaches to the carnival, with the force insisting on its use
  despite the Equality and Human Rights Commission saying police use of LFR is
  unlawful. The new claims come from Prof Pete Fussey, who led the only
  independent academic review of police use of facial recognition, is a former
  reviewer of LFR for the Met from 2018-19, and currently advises other forces
  in the UK and abroad on its use. The Met says it has reformed its use of LFR
  after a 2023 study it commissioned from the National Physical Laboratory (NPL)
  and it is now, in effect, bias-free. But Fussey said: “The claims the Met are
  making about the absence of bias from the NPL report are not substantiated by
  the facts in that report.” For LFR to work, the sensitivity of the system can
  be varied. The more sensitive it is the more people it will detect, but the
  higher its potential bias will be on racial, gender and age grounds. Zero is
  its most sensitive setting and one the least sensitive. The NPL report found
  there was bias at a setting of 0.56. At a setting of 0.6 it found seven cases
  where people in its test were wrongly flagged as wanted – a false positive.
  All were from ethnic minorities. The study results were gained after 178,000
  images were entered into the system. Four hundred volunteers walked past
  cameras approximately 10 times each, providing 4,000 chances for the system to
  correctly recognise them. They were contained in what the study estimated were
  crowds of more than 130,000 people at four sites in London and one in Cardiff.
  Testing took place in sunny conditions and totalled 34.5 hours, which Fussey
  said is shorter than in some other countries assessing LFR. From this sample,
  the report concluded there was no statistically significant bias at a setting
  of 0.6 or higher, a claim the Met has repeated to defend the use and expansion
  of LFR. Fussey said this was far too small a sample to support the Met’s
  claims. “The MPS [Metropolitan Police Service] consistently claim their system
  has been independently tested for bias. Examining this research reveals the
  data is insufficient to support the claims being made . “The decisive
  conclusions the Met are stating publicly are based on analysis of just seven
  false matches. This is from a system that has analysed millions of Londoners’
  faces. It is a weak statistical basis to make universal claims from such a
  small sample of false matches.” The Met now uses LFR at a sensitivity setting
  of 0.64, which the NPL study said produced no false matches. Fussey said:
  “According to their own research, false matches were not actually assessed at
  the settings they claim is free of bias, which is 0.64 or above. “Few, if any,
  in the scientific community would say the evidence is sufficient to support
  these claims extrapolated from such a small sample.” Fussey added: “The
  evaluation clearly states that bias exists in the algorithm, but claims this
  is eliminated if the system settings are changed. The issue here is that the
  system has not been adequately tested at these different settings, so it is
  difficult to support these claims.” The Met’s director of intelligence,
  Lindsey Chiswick, dismissed Fussey’s claims. “This is a factual report from a
  world-renowned organisation. The Met police’s commentary is based on what the
  independent report found,” she said. “When we use LFR at the setting of 0.64 –
  which is what we now use – there is no statistically significant bias. “We
  commissioned the study to understand where potential bias might lie in the
  algorithm and used the findings to mitigate that risk. “Its findings show us
  what level to use the algorithm at to avoid bias and we always operate above
  that level and in a fair way.” At Notting Hill this weekend warning signs will
  tell people LFR is in use, next to the vans containing the cameras which are
  linked to a database of wanted suspects. Police believe its use at two sites
  on the approaches to the carnival will act as a deterrent. At the carnival
  itself, police are preparing to use retrospective facial recognition to
  capture suspects for violence and assaults. Fussey said: “Few would doubt the
  right of police to use technology to keep the public safe, but this needs to
  be done with proper accountability measures and in accordance with human
  rights standards.” The Met claims that since 2024, LFR’s false positive rate
  has been one in every 33,000 cases. It declined to say how many faces had been
  scanned but it is understood to be in the hundreds of thousands. In 2024 there
  were 26 false matches, with eight so far in 2025. The Met says none of these
  people were detained, as once the computer system flags a match, the decision
  on whether to arrest is made by a police officer. Before the carnival, the Met
  had arrested 100 people, with 21 recalled to prison and 266 being banned from
  attending. The force also said it had seized 11 firearms and more than 40
  knives.
headline: >-
  Expert rejects Met police claim that study backs bias-free live facial
  recognition use
thumbnail: >-
  https://media.guim.co.uk/49f58085c10df3fae9369768c86bb8876dba3e9e/1576_0_3415_2734/500.jpg
slug: >-
  expert-rejects-met-police-claim-that-study-backs-bias-free-live-facial-recognition-use
webUrl: >-
  https://www.theguardian.com/technology/2025/aug/23/expert-rejects-met-police-claim-that-study-backs-bias-free-live-facial-recognition-use
---
The Metropolitan police’s claims that their use of live facial recognition is bias-free are not substantiated by the report they cite to support their case, a leading expert on the technology has said. The Met is planning its biggest and most high profile use of LFR yet this bank holiday weekend at Notting Hill carnival in west London. The Guardian understands it will be deployed at two sites on the approaches to the carnival, with the force insisting on its use despite the Equality and Human Rights Commission saying police use of LFR is unlawful. The new claims come from Prof Pete Fussey, who led the only independent academic review of police use of facial recognition, is a former reviewer of LFR for the Met from 2018-19, and currently advises other forces in the UK and abroad on its use. The Met says it has reformed its use of LFR after a 2023 study it commissioned from the National Physical Laboratory (NPL) and it is now, in effect, bias-free. But Fussey said: “The claims the Met are making about the absence of bias from the NPL report are not substantiated by the facts in that report.” For LFR to work, the sensitivity of the system can be varied. The more sensitive it is the more people it will detect, but the higher its potential bias will be on racial, gender and age grounds. Zero is its most sensitive setting and one the least sensitive. The NPL report found there was bias at a setting of 0.56. At a setting of 0.6 it found seven cases where people in its test were wrongly flagged as wanted – a false positive. All were from ethnic minorities. The study results were gained after 178,000 images were entered into the system. Four hundred volunteers walked past cameras approximately 10 times each, providing 4,000 chances for the system to correctly recognise them. They were contained in what the study estimated were crowds of more than 130,000 people at four sites in London and one in Cardiff. Testing took place in sunny conditions and totalled 34.5 hours, which Fussey said is shorter than in some other countries assessing LFR. From this sample, the report concluded there was no statistically significant bias at a setting of 0.6 or higher, a claim the Met has repeated to defend the use and expansion of LFR. Fussey said this was far too small a sample to support the Met’s claims. “The MPS [Metropolitan Police Service] consistently claim their system has been independently tested for bias. Examining this research reveals the data is insufficient to support the claims being made . “The decisive conclusions the Met are stating publicly are based on analysis of just seven false matches. This is from a system that has analysed millions of Londoners’ faces. It is a weak statistical basis to make universal claims from such a small sample of false matches.” The Met now uses LFR at a sensitivity setting of 0.64, which the NPL study said produced no false matches. Fussey said: “According to their own research, false matches were not actually assessed at the settings they claim is free of bias, which is 0.64 or above. “Few, if any, in the scientific community would say the evidence is sufficient to support these claims extrapolated from such a small sample.” Fussey added: “The evaluation clearly states that bias exists in the algorithm, but claims this is eliminated if the system settings are changed. The issue here is that the system has not been adequately tested at these different settings, so it is difficult to support these claims.” The Met’s director of intelligence, Lindsey Chiswick, dismissed Fussey’s claims. “This is a factual report from a world-renowned organisation. The Met police’s commentary is based on what the independent report found,” she said. “When we use LFR at the setting of 0.64 – which is what we now use – there is no statistically significant bias. “We commissioned the study to understand where potential bias might lie in the algorithm and used the findings to mitigate that risk. “Its findings show us what level to use the algorithm at to avoid bias and we always operate above that level and in a fair way.” At Notting Hill this weekend warning signs will tell people LFR is in use, next to the vans containing the cameras which are linked to a database of wanted suspects. Police believe its use at two sites on the approaches to the carnival will act as a deterrent. At the carnival itself, police are preparing to use retrospective facial recognition to capture suspects for violence and assaults. Fussey said: “Few would doubt the right of police to use technology to keep the public safe, but this needs to be done with proper accountability measures and in accordance with human rights standards.” The Met claims that since 2024, LFR’s false positive rate has been one in every 33,000 cases. It declined to say how many faces had been scanned but it is understood to be in the hundreds of thousands. In 2024 there were 26 false matches, with eight so far in 2025. The Met says none of these people were detained, as once the computer system flags a match, the decision on whether to arrest is made by a police officer. Before the carnival, the Met had arrested 100 people, with 21 recalled to prison and 266 being banned from attending. The force also said it had seized 11 firearms and more than 40 knives.
