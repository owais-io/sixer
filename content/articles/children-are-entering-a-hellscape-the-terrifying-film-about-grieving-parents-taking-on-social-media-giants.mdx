---
guardianId: >-
  film/2025/aug/04/cant-look-away-sextortion-children-grieving-parents-social-media-snapchat
webTitle: >-
  ‘Children are entering a hellscape’: the terrifying film about grieving
  parents taking on social media giants
sectionName: Film
webPublicationDate: '2025-08-04T15:00:36Z'
bodyText: >-
  In 2020, Amy Neville found her 14-year-old son Alexander dead in his bedroom.
  He had taken what he thought was an oxycodone pill, bought – according to
  Neville – from a drug dealer he met on Snapchat. The pill was a fake, laced
  with fentanyl. Four years later, his mum stood up in the California high
  school where Alex would have been a student to warn other parents and
  teenagers about social media. “We give our kids these smartphones. We let them
  have these apps. And that is the equivalent of dropping them off in the worst
  neighbourhood in our area.” Neville is featured alongside other bereaved
  parents in Can’t Look Away, a terrifying new documentary about kids and social
  media directed by Matthew O’Neill and Perri Peltz, based on extensive
  investigative reporting by Bloomberg News journalist Olivia Carville. It
  follows American families who are filing lawsuits against social media
  companies and campaigning for stricter legislation; they are represented by
  the Social Media Victims Law Center, a crusading legal firm run Matthew
  Bergman, a lawyer so charismatic he could probably play himself in a Hollywood
  movie. The conversation around teenagers and social media has evolved beyond
  kids using their phones at the table. In his 2024 bestseller The Anxious
  Generation, Jonathan Haidt warned of the links between young people’s mental
  health and smartphones. Last month, the technology secretary Peter Kyle
  apologised for the delay in legislation to keep children safe online.
  Australia plans to ban social media for under 16s from December. In Can’t Look
  Away, the agony on parents’ faces as they tell their stories, and relive the
  trauma, is hard to watch. Toney and Brandy Roberts filed a lawsuit against
  Meta over the death of their 14-year-old daughter Englyn in 2020; she killed
  herself after watching a video of a mock-hanging on Instagram. “The social
  media companies know that our children are so vulnerable,” Brandy tells the
  camera. “I feel that the only way that they’re going to be forced to change is
  through a lawsuit. So that’s why we’re joining this fight.” When I talk to the
  film’s directors before Can’t Look Away’s UK premiere, they do not mince their
  words. O’Neill says he previously had no idea how extreme the content that
  children are exposed to on social media is. “It’s so much more than just
  addiction, or screen time, or wasting time. What young people see is so
  different because of the algorithms. What they’re being fed, what they can’t
  look away from, this is not what they’re searching for. Children are
  essentially entering into a hellscape that adults don’t know about.”
  Algorithms decide what you see on social media, based in part on what you have
  previously liked or commented on, and how much time you’ve spent on other
  posts. If you linger on a piece of content, the algorithm will feed you more
  of the same. What that means is that teenagers don’t have to actively search
  for harmful material for it to appear in their feed. A 13-year-old girl might
  look for healthy eating advice and end up down a rabbit hole of pro-anorexia
  content. “It can very quickly turn very dark,” says O’Neill. Mason Edens was
  16 when he broke up with his girlfriend; normal teenage stuff his mum Jennie
  DeSerio thought. In his heartache, Mason turned to TikTok, searching for
  phrases such as: “My girlfriend broke up with me.” In the film, his mum plays
  one of the depressing videos that ended up in his feed. It shows a gun in a
  hand, then an image of blood splatter and the words: “My hand. My head.” Mason
  killed himself in November 2022. Jennie doesn’t believe that he’d ever
  searched for the term “suicide” on TikTok. O’Neill says he was shocked by
  Mason’s feed: “This is not someone crying. It’s not just sad music. It is an
  image of a gun going into a hand with the exhortation to blow your effing head
  off. That is not content that a product should be feeding to a child. I think
  we could all broadly agree on that as a society.” Is it possible, I ask, for
  the social media companies to filter out harmful content? “If Meta knows what
  I want to buy before I buy it, there’s no way they can’t figure out how to
  make sure children aren’t fed content that demonstrates how to die by
  suicide.” After screenings of Can’t Look Away, the film-makers often ask the
  kids in the audience if they have ever watched a suicide on social media.
  “Almost all the hands go up,” says co-director Peltz. In America, 95% of 13 to
  17-year-olds use social media. In 2022, social media companies made an
  estimated $11bn from advertising directed to under 18s in the US. The longer
  kids are glued to it, the more billions the companies make, which means there
  is a huge incentive to design sticky algorithms, says Peltz. “Why are they
  feeding children material that they can’t look away from? Because it keeps
  children on their sites for as long as possible. And we know from
  whistleblowers that that is a business plan. This is not an accident. They are
  prioritising time on screen over safety.” The film features interviews with
  such whistleblowers, who say companies have been warned that their products
  harm children. Arturo Béjar held senior positions at Facebook and Instagram,
  and became increasingly alarmed by their parent company Meta’s own research.
  In one poll, one in eight 13 to 15-year-olds said they had received an
  unwanted sexual advance on Instagram in the past week. Béjar emailed his
  concerns to Mark Zuckerberg, Sheryl Sandberg and other top executives. He says
  he never received a reply. Can’t Look Away tells the heart-breaking story of
  Jordan DeMay, a popular, outgoing 17-year-old from Michigan who killed himself
  after being blackmailed in a sextortion scam. In March 2022, he received a
  message on Instagram from someone he thought was a girl his own age. After
  some flirting, Jordan sent her nude photographs. Immediately, the threats
  started: send money or we’ll share the photos with your friends and family.
  Less than six hours after the first of these messages, Jordan was dead.
  Sextortion is one of the fastest growing cybercrimes. Peltz is keen to share
  with parents the advice she has picked up from several professionals about how
  to protect children. “Talk to your child. Tell them, ‘If this ever happens to
  you, do not be afraid to come to us.’ It’s very specific advice that can make
  a major difference.” Can’t Look Away ends with some real-life courtroom drama
  in Los Angeles. Amy Neville, the woman whose son took the fake oxycodone pill,
  is the lead plaintiff in a case against Snapchat by parents whose children
  died or were injured after allegedly buying fentanyl-laced drugs. Their
  lawsuit claims that Snapchat’s design makes it an ideal marketplace to sell
  illegal drugs, with its disappearing messages that make it difficult for
  police to trace illegal activity. Another feature is Quick Add, which suggests
  other users to add. Laura Marquez-Garrett is a lawyer at the Social Media
  Victims Law Center and explains how it works. “[A dealer will] just find one
  high school kid in your area. You add them, and then you add all their
  friends, and then you add their friends.” In a courtroom showdown, Snap Inc’s
  defence relies on a piece of US legislation drafted before Zuckerberg hit
  puberty. Section 230 of the Communications Decency Act of 1996 has for years
  acted as a shield (or a get-out-of-jail card, depending on your perspective)
  protecting social media companies from liability for user-generated content
  posted on their platforms. In court, Snap Inc’s attorney describes the
  platform as a tech-service provider, like a phone company. You wouldn’t sue a
  phone company if a drug deal was made over the phone. The back-and-forth
  between the lawyers and the judge is a gripping intellectual tennis match.
  Peltz tells me that parents often feel powerless. “But this is not a
  blame-the-parents situation. Companies need to make the changes so that these
  sites are responsible and are safe for children to be on. Parents can’t be
  expected to keep up with their children when it comes to digital advances.
  It’s time for these companies to stop blaming parents.” As for teenagers,
  people can be judgmental, she says. “I think it’s human nature to say, ‘Well
  my child wouldn’t buy drugs online.’ Or, ‘My child couldn’t be sextorted.’ The
  answer is that we can all hope that our children won’t do things like that.
  But children are children. We all know about the frontal cortex, that it
  doesn’t get fully developed until your 20s. Children make mistakes. They
  should be allowed to make mistakes and not have to die as a result.” • Can’t
  Look Away: The Case Against Social Media is in UK cinemas and streaming on
  jolt.film from 8 August • In the UK, the youth suicide charity Papyrus can be
  contacted on 0800 068 4141 or email pat@papyrus-uk.org, and in the UK and
  Ireland Samaritans can be contacted on freephone 116 123, or email
  jo@samaritans.org or jo@samaritans.ie. In the US, the National Suicide
  Prevention Lifeline is at 988 or chat for support. You can also text HOME to
  741741 to connect with a crisis text line counselor. In Australia, the crisis
  support service Lifeline is 13 11 14. Other international helplines can be
  found at befrienders.org
headline: >-
  ‘Children are entering a hellscape’: the terrifying film about grieving
  parents taking on social media giants
thumbnail: >-
  https://media.guim.co.uk/b862108339e7cf466179348e8392663d37599a2e/681_84_1239_991/500.jpg
slug: >-
  children-are-entering-a-hellscape-the-terrifying-film-about-grieving-parents-taking-on-social-media-giants
webUrl: >-
  https://www.theguardian.com/film/2025/aug/04/cant-look-away-sextortion-children-grieving-parents-social-media-snapchat
generatedAt: '2025-08-28T20:04:29.928Z'
source: guardian-api
---
In 2020, Amy Neville found her 14-year-old son Alexander dead in his bedroom. He had taken what he thought was an oxycodone pill, bought – according to Neville – from a drug dealer he met on Snapchat. The pill was a fake, laced with fentanyl. Four years later, his mum stood up in the California high school where Alex would have been a student to warn other parents and teenagers about social media. “We give our kids these smartphones. We let them have these apps. And that is the equivalent of dropping them off in the worst neighbourhood in our area.” Neville is featured alongside other bereaved parents in Can’t Look Away, a terrifying new documentary about kids and social media directed by Matthew O’Neill and Perri Peltz, based on extensive investigative reporting by Bloomberg News journalist Olivia Carville. It follows American families who are filing lawsuits against social media companies and campaigning for stricter legislation; they are represented by the Social Media Victims Law Center, a crusading legal firm run Matthew Bergman, a lawyer so charismatic he could probably play himself in a Hollywood movie. The conversation around teenagers and social media has evolved beyond kids using their phones at the table. In his 2024 bestseller The Anxious Generation, Jonathan Haidt warned of the links between young people’s mental health and smartphones. Last month, the technology secretary Peter Kyle apologised for the delay in legislation to keep children safe online. Australia plans to ban social media for under 16s from December. In Can’t Look Away, the agony on parents’ faces as they tell their stories, and relive the trauma, is hard to watch. Toney and Brandy Roberts filed a lawsuit against Meta over the death of their 14-year-old daughter Englyn in 2020; she killed herself after watching a video of a mock-hanging on Instagram. “The social media companies know that our children are so vulnerable,” Brandy tells the camera. “I feel that the only way that they’re going to be forced to change is through a lawsuit. So that’s why we’re joining this fight.” When I talk to the film’s directors before Can’t Look Away’s UK premiere, they do not mince their words. O’Neill says he previously had no idea how extreme the content that children are exposed to on social media is. “It’s so much more than just addiction, or screen time, or wasting time. What young people see is so different because of the algorithms. What they’re being fed, what they can’t look away from, this is not what they’re searching for. Children are essentially entering into a hellscape that adults don’t know about.” Algorithms decide what you see on social media, based in part on what you have previously liked or commented on, and how much time you’ve spent on other posts. If you linger on a piece of content, the algorithm will feed you more of the same. What that means is that teenagers don’t have to actively search for harmful material for it to appear in their feed. A 13-year-old girl might look for healthy eating advice and end up down a rabbit hole of pro-anorexia content. “It can very quickly turn very dark,” says O’Neill. Mason Edens was 16 when he broke up with his girlfriend; normal teenage stuff his mum Jennie DeSerio thought. In his heartache, Mason turned to TikTok, searching for phrases such as: “My girlfriend broke up with me.” In the film, his mum plays one of the depressing videos that ended up in his feed. It shows a gun in a hand, then an image of blood splatter and the words: “My hand. My head.” Mason killed himself in November 2022. Jennie doesn’t believe that he’d ever searched for the term “suicide” on TikTok. O’Neill says he was shocked by Mason’s feed: “This is not someone crying. It’s not just sad music. It is an image of a gun going into a hand with the exhortation to blow your effing head off. That is not content that a product should be feeding to a child. I think we could all broadly agree on that as a society.” Is it possible, I ask, for the social media companies to filter out harmful content? “If Meta knows what I want to buy before I buy it, there’s no way they can’t figure out how to make sure children aren’t fed content that demonstrates how to die by suicide.” After screenings of Can’t Look Away, the film-makers often ask the kids in the audience if they have ever watched a suicide on social media. “Almost all the hands go up,” says co-director Peltz. In America, 95% of 13 to 17-year-olds use social media. In 2022, social media companies made an estimated $11bn from advertising directed to under 18s in the US. The longer kids are glued to it, the more billions the companies make, which means there is a huge incentive to design sticky algorithms, says Peltz. “Why are they feeding children material that they can’t look away from? Because it keeps children on their sites for as long as possible. And we know from whistleblowers that that is a business plan. This is not an accident. They are prioritising time on screen over safety.” The film features interviews with such whistleblowers, who say companies have been warned that their products harm children. Arturo Béjar held senior positions at Facebook and Instagram, and became increasingly alarmed by their parent company Meta’s own research. In one poll, one in eight 13 to 15-year-olds said they had received an unwanted sexual advance on Instagram in the past week. Béjar emailed his concerns to Mark Zuckerberg, Sheryl Sandberg and other top executives. He says he never received a reply. Can’t Look Away tells the heart-breaking story of Jordan DeMay, a popular, outgoing 17-year-old from Michigan who killed himself after being blackmailed in a sextortion scam. In March 2022, he received a message on Instagram from someone he thought was a girl his own age. After some flirting, Jordan sent her nude photographs. Immediately, the threats started: send money or we’ll share the photos with your friends and family. Less than six hours after the first of these messages, Jordan was dead. Sextortion is one of the fastest growing cybercrimes. Peltz is keen to share with parents the advice she has picked up from several professionals about how to protect children. “Talk to your child. Tell them, ‘If this ever happens to you, do not be afraid to come to us.’ It’s very specific advice that can make a major difference.” Can’t Look Away ends with some real-life courtroom drama in Los Angeles. Amy Neville, the woman whose son took the fake oxycodone pill, is the lead plaintiff in a case against Snapchat by parents whose children died or were injured after allegedly buying fentanyl-laced drugs. Their lawsuit claims that Snapchat’s design makes it an ideal marketplace to sell illegal drugs, with its disappearing messages that make it difficult for police to trace illegal activity. Another feature is Quick Add, which suggests other users to add. Laura Marquez-Garrett is a lawyer at the Social Media Victims Law Center and explains how it works. “[A dealer will] just find one high school kid in your area. You add them, and then you add all their friends, and then you add their friends.” In a courtroom showdown, Snap Inc’s defence relies on a piece of US legislation drafted before Zuckerberg hit puberty. Section 230 of the Communications Decency Act of 1996 has for years acted as a shield (or a get-out-of-jail card, depending on your perspective) protecting social media companies from liability for user-generated content posted on their platforms. In court, Snap Inc’s attorney describes the platform as a tech-service provider, like a phone company. You wouldn’t sue a phone company if a drug deal was made over the phone. The back-and-forth between the lawyers and the judge is a gripping intellectual tennis match. Peltz tells me that parents often feel powerless. “But this is not a blame-the-parents situation. Companies need to make the changes so that these sites are responsible and are safe for children to be on. Parents can’t be expected to keep up with their children when it comes to digital advances. It’s time for these companies to stop blaming parents.” As for teenagers, people can be judgmental, she says. “I think it’s human nature to say, ‘Well my child wouldn’t buy drugs online.’ Or, ‘My child couldn’t be sextorted.’ The answer is that we can all hope that our children won’t do things like that. But children are children. We all know about the frontal cortex, that it doesn’t get fully developed until your 20s. Children make mistakes. They should be allowed to make mistakes and not have to die as a result.” • Can’t Look Away: The Case Against Social Media is in UK cinemas and streaming on jolt.film from 8 August • In the UK, the youth suicide charity Papyrus can be contacted on 0800 068 4141 or email pat@papyrus-uk.org, and in the UK and Ireland Samaritans can be contacted on freephone 116 123, or email jo@samaritans.org or jo@samaritans.ie. In the US, the National Suicide Prevention Lifeline is at 988 or chat for support. You can also text HOME to 741741 to connect with a crisis text line counselor. In Australia, the crisis support service Lifeline is 13 11 14. Other international helplines can be found at befrienders.org
