---
guardianId: >-
  uk-news/2025/aug/16/facial-recognition-cameras-too-racially-biased-to-use-at-notting-hill-carnival-say-campaigners
webTitle: >-
  Facial recognition cameras too racially biased to use at Notting Hill
  carnival, say campaigners 
sectionName: UK news
webPublicationDate: '2025-08-16T09:00:58Z'
bodyText: >-
  The Met commissioner should scrap plans to deploy live facial recognition
  (LFR) at next weekend’s Notting Hill carnival because the technology is riven
  with “racial bias” and subject to a legal challenge, 11 civil liberty and
  anti-racist groups have demanded. A letter sent to Mark Rowley warns that use
  of instant face-matching cameras at an event that celebrates the
  African-Caribbean community “will only exacerbate concerns about abuses of
  state power and racial discrimination within your force”. The Runnymede Trust,
  Liberty, Big Brother Watch, Race on the Agenda, and Human Rights Watch are
  among those who claim the technology “is less accurate for women and people of
  colour”. The demand comes just days after ministers ramped up the deployment
  of vans fixed with facial recognition technology to nine forces across England
  and Wales. The Met said last month it would deploy specially mounted cameras
  at entries and exits of the two-day event in west London. As many as 2 million
  people attend the second biggest street festival in the world every year, held
  on the August bank holiday weekend. In the letter seen by the Guardian, the
  signatories say: “The choice to deploy LFR at Notting Hill carnival unfairly
  targets the community that carnival exists to celebrate. “The Met has been
  found to be institutionally racist by Baroness Casey’s independent review and
  trust in the Met has been badly damaged by discriminatory policing. “Targeting
  Notting Hill carnival with live facial recognition technology will only
  exacerbate concerns about abuses of state power and racial discrimination
  within your force.” The letter says that since the Met announced its Notting
  Hill plan, a high court challenge has been launched by the anti-knife
  campaigner Shaun Thompson. A Black British man, Thompson was wrongly
  identified as a criminal, held by police, and then faced demands from officers
  for his fingerprints. “Mr Thompson was returning from volunteering with Street
  Fathers, a youth advocacy and anti-violence community organisation, when he
  was surrounded by officers and held for half an hour. He has likened the
  discriminatory impacts of LFR to ‘stop and search on steroids’,” the letter
  said. Campaigners claim the police have been allowed to “self-regulate” their
  use of the technology. Officers have in the past used a setting that was
  subsequently shown to disproportionately misidentify Black people. An
  independent report by the public corporation the National Physical Laboratory
  found that the Met’s LFR technology, which is called NeoFace, is less accurate
  for women and people of colour when deployed at certain settings. The report’s
  author, Dr Tony Mansfield, acknowledged that “if the system is run at low and
  easy thresholds, the system starts showing a bias against black males and
  females combined”. There is no legal obligation on the police to run the
  technology on higher settings, the letter says. In 2018, a researcher at MIT
  Media Lab in the US concluded that software supplied by three companies made
  mistakes in 21% to 35% of cases for darker-skinned women. By contrast, the
  error rate for light-skinned men was less than 1%. The other signatories are
  senior figures in Privacy Watch, Privacy International, Race Equality First,
  Open Rights Group, Access Now, StopWatch and Statewatch. The Met said last
  month the cameras would be used on the approach to and exit from the carnival,
  “outside the boundaries of the event” itself, to help officers “identify and
  intercept” people who pose a public safety risk. The Met has said it will only
  use the technology at settings that demonstrate no racial bias to uncover
  people wanted for the most serious offences such as knife crime and sexual
  assaults. However, civil liberty groups were dismayed to discover that the
  technology has previously been used by police in Wales to target ticket touts.
  About 7,000 officers and staff will be deployed on each day of the carnival,
  the Met said. LFR cameras on the approach to the carnival will search for
  people who are shown as missing and people who are subject to sexual harm
  prevention orders, police said. Screening arches will be deployed at some of
  the busiest entry points, where stop-and-search powers will be used. The event
  is still community-led, but senior politicians have expressed concerns about
  its safety, resulting in demands that it should be moved to Hyde Park or be
  ticketed to prevent crushes in narrow streets. Yvette Cooper, the home
  secretary, said last week that she would draw up a new legal framework for the
  use of LFR. “Facial recognition will be used in a targeted way to identify sex
  offenders or people wanted for the most serious crimes who the police have not
  been able to find,” she said. The Met and South Wales police have been testing
  the technology. The Met says it has made 580 arrests using LFR for offences
  including rape, domestic abuse, knife crime, grievous bodily harm and robbery,
  including 52 registered sex offenders arrested for breaching their conditions.
  The Met deputy assistant commissioner Matt Ward, who is in charge of the
  policing operation for carnival this year, said the force was aware there were
  still “misconceptions” about the use of live facial recognition in Black and
  other ethnic minority communities. “It is right that we make the best use of
  available technology to support officers to do their job more effectively.
  That is why we will be using LFR cameras on the approach to and from carnival,
  outside the boundaries of the event itself. Live facial recognition is a
  reliable and effective tool. It has led to more than 1,000 arrests since the
  start of 2024. “Independent testing by the National Physical Laboratory found
  that at the thresholds the MPS uses the system, it is accurate and balanced
  with regard to ethnicity and gender, but we know there are still
  misconceptions about its use, particularly in Black and other minority ethnic
  communities.”
headline: >-
  Facial recognition cameras too racially biased to use at Notting Hill
  carnival, say campaigners 
thumbnail: >-
  https://media.guim.co.uk/af3da4e232da8e922c2ac6de3cccd9c5d5ce8962/0_0_3766_3013/500.jpg
slug: >-
  facial-recognition-cameras-too-racially-biased-to-use-at-notting-hill-carnival-say-campaigners
webUrl: >-
  https://www.theguardian.com/uk-news/2025/aug/16/facial-recognition-cameras-too-racially-biased-to-use-at-notting-hill-carnival-say-campaigners
generatedAt: '2025-08-28T20:04:23.640Z'
source: guardian-api
---
The Met commissioner should scrap plans to deploy live facial recognition (LFR) at next weekend’s Notting Hill carnival because the technology is riven with “racial bias” and subject to a legal challenge, 11 civil liberty and anti-racist groups have demanded. A letter sent to Mark Rowley warns that use of instant face-matching cameras at an event that celebrates the African-Caribbean community “will only exacerbate concerns about abuses of state power and racial discrimination within your force”. The Runnymede Trust, Liberty, Big Brother Watch, Race on the Agenda, and Human Rights Watch are among those who claim the technology “is less accurate for women and people of colour”. The demand comes just days after ministers ramped up the deployment of vans fixed with facial recognition technology to nine forces across England and Wales. The Met said last month it would deploy specially mounted cameras at entries and exits of the two-day event in west London. As many as 2 million people attend the second biggest street festival in the world every year, held on the August bank holiday weekend. In the letter seen by the Guardian, the signatories say: “The choice to deploy LFR at Notting Hill carnival unfairly targets the community that carnival exists to celebrate. “The Met has been found to be institutionally racist by Baroness Casey’s independent review and trust in the Met has been badly damaged by discriminatory policing. “Targeting Notting Hill carnival with live facial recognition technology will only exacerbate concerns about abuses of state power and racial discrimination within your force.” The letter says that since the Met announced its Notting Hill plan, a high court challenge has been launched by the anti-knife campaigner Shaun Thompson. A Black British man, Thompson was wrongly identified as a criminal, held by police, and then faced demands from officers for his fingerprints. “Mr Thompson was returning from volunteering with Street Fathers, a youth advocacy and anti-violence community organisation, when he was surrounded by officers and held for half an hour. He has likened the discriminatory impacts of LFR to ‘stop and search on steroids’,” the letter said. Campaigners claim the police have been allowed to “self-regulate” their use of the technology. Officers have in the past used a setting that was subsequently shown to disproportionately misidentify Black people. An independent report by the public corporation the National Physical Laboratory found that the Met’s LFR technology, which is called NeoFace, is less accurate for women and people of colour when deployed at certain settings. The report’s author, Dr Tony Mansfield, acknowledged that “if the system is run at low and easy thresholds, the system starts showing a bias against black males and females combined”. There is no legal obligation on the police to run the technology on higher settings, the letter says. In 2018, a researcher at MIT Media Lab in the US concluded that software supplied by three companies made mistakes in 21% to 35% of cases for darker-skinned women. By contrast, the error rate for light-skinned men was less than 1%. The other signatories are senior figures in Privacy Watch, Privacy International, Race Equality First, Open Rights Group, Access Now, StopWatch and Statewatch. The Met said last month the cameras would be used on the approach to and exit from the carnival, “outside the boundaries of the event” itself, to help officers “identify and intercept” people who pose a public safety risk. The Met has said it will only use the technology at settings that demonstrate no racial bias to uncover people wanted for the most serious offences such as knife crime and sexual assaults. However, civil liberty groups were dismayed to discover that the technology has previously been used by police in Wales to target ticket touts. About 7,000 officers and staff will be deployed on each day of the carnival, the Met said. LFR cameras on the approach to the carnival will search for people who are shown as missing and people who are subject to sexual harm prevention orders, police said. Screening arches will be deployed at some of the busiest entry points, where stop-and-search powers will be used. The event is still community-led, but senior politicians have expressed concerns about its safety, resulting in demands that it should be moved to Hyde Park or be ticketed to prevent crushes in narrow streets. Yvette Cooper, the home secretary, said last week that she would draw up a new legal framework for the use of LFR. “Facial recognition will be used in a targeted way to identify sex offenders or people wanted for the most serious crimes who the police have not been able to find,” she said. The Met and South Wales police have been testing the technology. The Met says it has made 580 arrests using LFR for offences including rape, domestic abuse, knife crime, grievous bodily harm and robbery, including 52 registered sex offenders arrested for breaching their conditions. The Met deputy assistant commissioner Matt Ward, who is in charge of the policing operation for carnival this year, said the force was aware there were still “misconceptions” about the use of live facial recognition in Black and other ethnic minority communities. “It is right that we make the best use of available technology to support officers to do their job more effectively. That is why we will be using LFR cameras on the approach to and from carnival, outside the boundaries of the event itself. Live facial recognition is a reliable and effective tool. It has led to more than 1,000 arrests since the start of 2024. “Independent testing by the National Physical Laboratory found that at the thresholds the MPS uses the system, it is accurate and balanced with regard to ethnicity and gender, but we know there are still misconceptions about its use, particularly in Black and other minority ethnic communities.”
