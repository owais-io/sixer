---
guardianId: >-
  law/2025/sep/03/lawyer-caught-using-ai-generated-false-citations-in-court-case-penalised-in-australian-first
webTitle: >-
  Lawyer caught using AI-generated false citations in court case penalised in
  Australian first 
sectionName: Law
webPublicationDate: '2025-09-03T03:44:44Z'
bodyText: >-
  A Victorian lawyer has become the first in Australia to face professional
  sanctions for using artificial intelligence in a court case, being stripped of
  his ability to practise as a principal lawyer after AI generated false
  citations that he had failed to verify. Guardian Australia reported in October
  last year that in a 19 July 2024 hearing, the anonymous solicitor representing
  a husband in a dispute between a married couple provided the court with a list
  of prior cases that had been requested by Justice Amanda Humphreys in relation
  to an enforcement application in the case. When Humphreys returned to her
  chambers, she said in a ruling that neither herself nor her associates were
  able to identify the cases in the list. When the matter returned to court the
  lawyer confirmed that the list had been prepared using legal software that
  utilised AI. He acknowledged he did not verify the accuracy of the information
  before submitting it to the court. The lawyer offered an “unconditional
  apology” to the court and said he would “take the lessons learned to heart”
  and asked not to be referred for investigation. He said he did not fully
  understand how the software worked, and acknowledged the need to verify
  AI-assisted research for accuracy. He made a payment to the solicitors for the
  other party for the costs of the thrown away hearing. Sign up: AU Breaking
  News email Humphreys said she accepted the apology and acknowledged the stress
  it caused meant it was unlikely to be repeated, but a referral for
  investigation was important given it was in the public interest for the
  Victorian Legal Services Board and Commissioner to examine professional
  conduct issues, given the increasing use of AI tools in law. The lawyer was
  referred to the Victorian Legal Services Board for investigation, in what was
  one of the first reported cases in Australia of a lawyer being caught out
  using AI in court that generated false citations. The Victorian Legal Services
  Board confirmed on Tuesday that the lawyer had his practising certificate
  varied on 19 August as a result of the investigation, meaning he was no longer
  entitled to practise as a principal lawyer, not authorised to handle trust
  money, would no longer operate his own law practice, and would only practise
  as an employee solicitor. The lawyer will undertake supervised legal practice
  for a period of two years, with the lawyer and his supervisor reporting to the
  board on a quarterly basis in that time. “The board’s regulatory action in
  this matter demonstrates our commitment to ensuring legal practitioners who
  choose to use AI in their legal practice do so in a responsible way that is
  consistent with their obligations,” a spokesperson said. Since this case,
  there have been more than 20 other reported cases in Australian courts where
  lawyers or self-represented litigants have been found to have used artificial
  intelligence in the preparation of court documents that led to those documents
  containing fake citations. Lawyers in Western Australia and New South Wales
  have also been referred to their own state regulatory bodies over the
  practice. There has also been at least one case in Australia where someone
  claimed a document had been prepared using ChatGPT, only for the court to
  determine the document in question was created before ChatGPT was available to
  the public. Courts and law groups recognise that AI will play a role in legal
  processes, but continue to warn that it does not diminish lawyers’
  professional judgment. “Where these tools are utilised by lawyers, this must
  be done with extreme care,” the Law Council of Australia’s president, Juliana
  Warner, told Guardian Australia last month. “Lawyers must always keep front of
  mind their professional and ethical obligations to the court and to their
  clients.” Warner said courts were regarding cases where AI had generated fake
  citations as a “serious concern” but added that given the widespread use of
  generative AI, a broadly framed prohibition on its use in legal proceedings
  would be “neither practical nor proportionate, and risks hindering innovation
  and access to justice”.
headline: >-
  Lawyer caught using AI-generated false citations in court case penalised in
  Australian first 
thumbnail: >-
  https://media.guim.co.uk/cd380f0ce442e1fc71ead1ccffc2dce15094e1b7/599_0_3567_2855/500.jpg
slug: >-
  lawyer-caught-using-ai-generated-false-citations-in-court-case-penalised-in-australian-first
webUrl: >-
  https://www.theguardian.com/law/2025/sep/03/lawyer-caught-using-ai-generated-false-citations-in-court-case-penalised-in-australian-first
generatedAt: '2025-09-03T09:11:25.828Z'
source: guardian-api
---
A Victorian lawyer has become the first in Australia to face professional sanctions for using artificial intelligence in a court case, being stripped of his ability to practise as a principal lawyer after AI generated false citations that he had failed to verify. Guardian Australia reported in October last year that in a 19 July 2024 hearing, the anonymous solicitor representing a husband in a dispute between a married couple provided the court with a list of prior cases that had been requested by Justice Amanda Humphreys in relation to an enforcement application in the case. When Humphreys returned to her chambers, she said in a ruling that neither herself nor her associates were able to identify the cases in the list. When the matter returned to court the lawyer confirmed that the list had been prepared using legal software that utilised AI. He acknowledged he did not verify the accuracy of the information before submitting it to the court. The lawyer offered an “unconditional apology” to the court and said he would “take the lessons learned to heart” and asked not to be referred for investigation. He said he did not fully understand how the software worked, and acknowledged the need to verify AI-assisted research for accuracy. He made a payment to the solicitors for the other party for the costs of the thrown away hearing. Sign up: AU Breaking News email Humphreys said she accepted the apology and acknowledged the stress it caused meant it was unlikely to be repeated, but a referral for investigation was important given it was in the public interest for the Victorian Legal Services Board and Commissioner to examine professional conduct issues, given the increasing use of AI tools in law. The lawyer was referred to the Victorian Legal Services Board for investigation, in what was one of the first reported cases in Australia of a lawyer being caught out using AI in court that generated false citations. The Victorian Legal Services Board confirmed on Tuesday that the lawyer had his practising certificate varied on 19 August as a result of the investigation, meaning he was no longer entitled to practise as a principal lawyer, not authorised to handle trust money, would no longer operate his own law practice, and would only practise as an employee solicitor. The lawyer will undertake supervised legal practice for a period of two years, with the lawyer and his supervisor reporting to the board on a quarterly basis in that time. “The board’s regulatory action in this matter demonstrates our commitment to ensuring legal practitioners who choose to use AI in their legal practice do so in a responsible way that is consistent with their obligations,” a spokesperson said. Since this case, there have been more than 20 other reported cases in Australian courts where lawyers or self-represented litigants have been found to have used artificial intelligence in the preparation of court documents that led to those documents containing fake citations. Lawyers in Western Australia and New South Wales have also been referred to their own state regulatory bodies over the practice. There has also been at least one case in Australia where someone claimed a document had been prepared using ChatGPT, only for the court to determine the document in question was created before ChatGPT was available to the public. Courts and law groups recognise that AI will play a role in legal processes, but continue to warn that it does not diminish lawyers’ professional judgment. “Where these tools are utilised by lawyers, this must be done with extreme care,” the Law Council of Australia’s president, Juliana Warner, told Guardian Australia last month. “Lawyers must always keep front of mind their professional and ethical obligations to the court and to their clients.” Warner said courts were regarding cases where AI had generated fake citations as a “serious concern” but added that given the widespread use of generative AI, a broadly framed prohibition on its use in legal proceedings would be “neither practical nor proportionate, and risks hindering innovation and access to justice”.
