---
guardianId: >-
  technology/2025/aug/22/tiktok-uk-moderator-jobs-at-risk-despite-new-online-safety-rules
webTitle: Hundreds of TikTok UK moderator jobs at risk despite new online safety rules
sectionName: Technology
webPublicationDate: '2025-08-22T12:40:01Z'
bodyText: >-
  TikTok has put hundreds of UK content moderators’ jobs at risk, even as
  tighter rules come into effect to stop the spread of harmful material online.
  The viral video app said several hundred jobs in its trust and safety team
  could be affected in the UK, as well as south and south-east Asia, as part of
  a global reorganisation. Their work will be reallocated to other European
  offices and third-party providers, with some trust and safety jobs remaining
  in the UK, the company said. It is part of a wider move at TikTok to rely on
  artificial intelligence for moderation. More than 85% of the content removed
  for violating its community guidelines is identified and taken down by
  automation, according to the platform. The cuts come despite the recent
  introduction of new UK online safety rules, which require companies to
  introduce age checks on users attempting to view potentially harmful content.
  Companies can be fined up to £18m or 10% of global turnover for breaches,
  whichever is greater. John Chadfield of the Communication Workers Union said
  replacing workers with AI in content moderation could put the safety of
  millions of TikTok users at risk. “TikTok workers have long been sounding the
  alarm over the real-world costs of cutting human moderation teams in favour of
  hastily developed, immature AI alternatives,” he said. TikTok, which is owned
  by the Chinese tech group ByteDance, employs more than 2,500 staff in the UK.
  Over the past year, TikTok has been cutting trust and safety staff across the
  world, often substituting workers with automated systems. In September, the
  company fired its entire team of 300 content moderators in the Netherlands. In
  October, it then announced it would replace about 500 content moderation
  employees in Malaysia as part of its shift towards AI. Last week, TikTok
  workers in Germany held strikes over layoffs in its trust and safety team.
  Meanwhile, business at TikTok is booming. Accounts filed to Companies House
  this week, which include its operations in the UK and Europe, showed revenues
  grew 38% to $6.3bn (£4.7bn) in 2024 compared with the year prior. Its
  operating loss narrowed from $1.4bn in 2023 to $485m. A TikTok spokesperson
  said the company was “continuing a reorganisation that we started last year to
  strengthen our global operating model for trust and safety, which includes
  concentrating our operations in fewer locations globally to ensure that we
  maximise effectiveness and speed as we evolve this critical function for the
  company with the benefit of technological advancements”.
headline: Hundreds of TikTok UK moderator jobs at risk despite new online safety rules
thumbnail: >-
  https://media.guim.co.uk/24ab2055247777d44388869d1ab961e4008e64de/398_0_3478_2784/500.jpg
slug: hundreds-of-tiktok-uk-moderator-jobs-at-risk-despite-new-online-safety-rules
webUrl: >-
  https://www.theguardian.com/technology/2025/aug/22/tiktok-uk-moderator-jobs-at-risk-despite-new-online-safety-rules
---
TikTok has put hundreds of UK content moderators’ jobs at risk, even as tighter rules come into effect to stop the spread of harmful material online. The viral video app said several hundred jobs in its trust and safety team could be affected in the UK, as well as south and south-east Asia, as part of a global reorganisation. Their work will be reallocated to other European offices and third-party providers, with some trust and safety jobs remaining in the UK, the company said. It is part of a wider move at TikTok to rely on artificial intelligence for moderation. More than 85% of the content removed for violating its community guidelines is identified and taken down by automation, according to the platform. The cuts come despite the recent introduction of new UK online safety rules, which require companies to introduce age checks on users attempting to view potentially harmful content. Companies can be fined up to £18m or 10% of global turnover for breaches, whichever is greater. John Chadfield of the Communication Workers Union said replacing workers with AI in content moderation could put the safety of millions of TikTok users at risk. “TikTok workers have long been sounding the alarm over the real-world costs of cutting human moderation teams in favour of hastily developed, immature AI alternatives,” he said. TikTok, which is owned by the Chinese tech group ByteDance, employs more than 2,500 staff in the UK. Over the past year, TikTok has been cutting trust and safety staff across the world, often substituting workers with automated systems. In September, the company fired its entire team of 300 content moderators in the Netherlands. In October, it then announced it would replace about 500 content moderation employees in Malaysia as part of its shift towards AI. Last week, TikTok workers in Germany held strikes over layoffs in its trust and safety team. Meanwhile, business at TikTok is booming. Accounts filed to Companies House this week, which include its operations in the UK and Europe, showed revenues grew 38% to $6.3bn (£4.7bn) in 2024 compared with the year prior. Its operating loss narrowed from $1.4bn in 2023 to $485m. A TikTok spokesperson said the company was “continuing a reorganisation that we started last year to strengthen our global operating model for trust and safety, which includes concentrating our operations in fewer locations globally to ensure that we maximise effectiveness and speed as we evolve this critical function for the company with the benefit of technological advancements”.
